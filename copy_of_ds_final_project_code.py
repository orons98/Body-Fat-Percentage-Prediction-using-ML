# -*- coding: utf-8 -*-
"""Copy of DS Final Project Code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eOQjKAiGuureeWl_FtyY7Naye2C-qIzF
"""

# Import libraries for data handling, modelling and viualisation

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Libraries for training, testing and tuning machine learning models
from sklearn.model_selection import train_test_split, RandomizedSearchCV

# Import basic Linear Regression model
from sklearn.linear_model import LinearRegression

# Import a complex random forest model
from sklearn.ensemble import RandomForestRegressor

# Import XGBoost model
from xgboost import XGBRegressor

# Testing efficacy of the model
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Import to scale the features so they’re on the same level
from sklearn.preprocessing import StandardScaler

# Import for running statistical models like OLS regression
import statsmodels.api as sm

# Mount Google drive to access dataset file
from google.colab import drive
drive.mount('/content/drive')

file_path = "/content/drive/MyDrive/Colab Notebooks/Body Fat percentage dataset/bodyfat.csv"
df = pd.read_csv(file_path)

# Display basic information about the datatset
print(df.info())

# Display first few rows of the dataset information
print(df.head())

# Check for missing data for each column. Fill any missing values with median of of each column
df.fillna(df.median(), inplace =True)
print(df.isnull().sum())

"""## Dataset Metrics
1. Density determined from underwater weighing

2. Body fat percentage (Siri's 1956 equation)
3. Age (years)
4. Weight (lbs)
5. Height (inches)
6. Neck circumferemce (cm)
7. Chest circumference (cm)
8. Abdomen 2 circumference (cm)
9. Hip circumference (cm)
10. Thigh circumference (cm)
11. Knee circumference (cm)
12. Ankle circumference (cm)
13. Biceps (extended) circumference (cm)
14. Wrist circumference (cm)



"""

# Plot correlation matrix to show which features are stronly related
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm", fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap of Body Fat Dataset")
plt.show()

# Distribution plot for Body Fat
sns.histplot(df["BodyFat"], bins=20, kde=True)
plt.title("Distribution of Body Fat Percentage")
plt.xlabel("Body Fat")
plt.ylabel("Count")
plt.show()

# Boxplot of selected body measurements
sns.boxplot(data=df[["Weight", "Chest", "Abdomen", "Hip"]])
plt.title("Boxplot of Body Measurements")
plt.show()

# Scatter plot for Abodomen vs Bodyfat
sns.scatterplot(x="Abdomen", y="BodyFat", data=df)
plt.title("Abdomen Circumference vs Body Fat Percentage")
plt.show()

# Pairplot for selected features (not sure on using this visualisation)
sns.pairplot(df[["Abdomen", "Chest", "Hip", "Weight", "BodyFat"]])
plt.suptitle("Pairwise Relationship", y= 1.02)
plt.show()

#Feature Selection. Sets X to be all the features except BodyFat
X = df.drop(columns=["BodyFat", "Density"])

# Sets y to be Body fat as output variable
y = df["BodyFat"]

#Standardise features for regression. Creates a scaler to standardise our values
scaler = StandardScaler()

# scales X and keeps the column names
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Function to do backward stepwise feature selection
def backward_stepwise_selection(X_data, y_data, alpha= 0.05):
  #All the features
  remaining = list(X_data.columns)
  # Backward Regression until all features are removed
  while len(remaining) > 0:
    # Constant column (for intercept)
    X_selected = sm.add_constant(X_data[remaining])
    # Fit an ordinary least squares regression model
    model = sm.OLS(y_data, X_selected).fit()
    # Get the p-values, skip the constant
    p_values = model.pvalues.iloc[1:]
    # Find the biggest p-value
    max_p = p_values.max()
    # If it's too big, the feature is not useful
    if max_p >= alpha:
      # Find the feature with the biggest p-value
      remove_features = p_values.idxmax()
      # Remove that feature
      remaining.remove(remove_features)
    else:
      # Stop if all remaining features are useful
        break
        # Return the list of useful features
  return remaining

X_scaled = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)
selected_features = backward_stepwise_selection(X_scaled, y)

print("Selected Features:", selected_features)

# Make a new version of X with only the selected features
final_features = df[selected_features]

# Split into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(final_features, y, test_size=0.2, random_state=42)

# Scale the training features
X_train_scaled = scaler.fit_transform(X_train)

# Scale the test features
X_test_scaled = scaler.transform(X_test)

# Linear Regression backwards stepwise
lr_model = LinearRegression()

# Train it on the training data
lr_model.fit(X_train_scaled, y_train)

# Predict body fat for the test set
y_pred_lr = lr_model.predict(X_test_scaled)

# Function to print out how well a model did
def evaluate_lr_model_metrics(true_vals, predictions, model_name):
  mse = mean_squared_error(true_vals, predictions)
  mae = mean_absolute_error(true_vals, predictions)
  r2 = r2_score(true_vals, predictions)

  print("\n---", model_name, "Evaluation ---")
  print("MSE:", round(mse, 2))
  print("MAE:", round(mae, 2))
  print("R^2 Score:", round(r2, 2))

evaluate_lr_model_metrics(y_test, y_pred_lr, "LR (Backward Stepwise)")

"""Note: Feature scaling applied only for the linear regression model, as it is sensitive to feature magnitudes. For Random Forest and XGBoost, scaling was intentionally removed, as these tree-based models are not influenced by feature scales and splitting decisions are made based on thresholds rather than distances."""

# Random Forest
rf_model = RandomForestRegressor(random_state=42)

# Randomised Search
rf_param = {
    'n_estimators': np.arange(50, 300, 50),
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

tune_rf = RandomizedSearchCV(rf_model, rf_param, n_iter=20, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, random_state=42)
tune_rf.fit(X_train, y_train)
rf_best = tune_rf.best_estimator_
y_pred_rf = rf_best.predict(X_test)

# XGBoost Regressor
xgb_model = XGBRegressor(objective="reg:squarederror", random_state=42)

xgb_param = {
    'n_estimators': np.arange(50, 300, 50),
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 6, 10, 15],
    'subsample': [0.6, 0.8, 1.0]
}

tune_xgb = RandomizedSearchCV(xgb_model, xgb_param, n_iter=20, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, random_state=42)
tune_xgb.fit(X_train, y_train)
xgb_best = tune_xgb.best_estimator_
y_pred_xgb = xgb_best.predict(X_test)

# Evaluation Function
def evaluate_model(y_test, y_pred, model_name):
    mse = mean_squared_error(y_test, y_pred)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"\nEvaluating {model_name}:")
    print("Mean Squared Error (MSE):", round(mse, 2))
    print("Mean Absolute Error (MAE):", round(mae, 2))
    print("R-squared (R2):", round(r2, 2))
    print("-" * 40)

# Evaluate XGBboost and Random Forest Models
evaluate_model(y_test, y_pred_lr, "Linear Regression")
evaluate_model(y_test, y_pred_rf, "Random Forest")
evaluate_model(y_test, y_pred_xgb, "XGBoost")

# Model Comparison Table
model_comparison = pd.DataFrame({
    "Model": ["Linear Regression", "Random Forest", "XGBoost"],
    "RMSE": [np.sqrt(mean_squared_error(y_test, y_pred_lr)),
             np.sqrt(mean_squared_error(y_test, y_pred_rf)),
             np.sqrt(mean_squared_error(y_test, y_pred_xgb))],
    "R² Score": [r2_score(y_test, y_pred_lr),
                 r2_score(y_test, y_pred_rf),
                 r2_score(y_test, y_pred_xgb)],
    "MAE": [mean_absolute_error(y_test, y_pred_lr),
            mean_absolute_error(y_test, y_pred_rf),
            mean_absolute_error(y_test, y_pred_xgb)]
})

# Print model comparison table
print("\nModel Performance Comparison:")
print(model_comparison)

# Visualising model performance with bar plot
plt.figure(figsize=(10, 5))
sns.barplot(x="Model", y="RMSE", data=model_comparison, palette="viridis")
plt.title("Model RMSE Comparison")
plt.show()

"""Note: Tested feature selection using three methods as I was getting a high VIF and was unable to use the features
1. Lowering correlation threshold to (0.40+) from 0.60+
2. Using Feature importance (Random Forest)
3. Manually Selecting Featires (Domain Knowledge)

Reason: when applying a correlation threshold only Bodyfat itself remained - no independen features had a strong enough correlation to be selected.

Creates 2 problems:
1. having no predictors (features) left for the model to learn from
2. Model will not be useful

"""

# Residual plot for LR
residuals = y_test - y_pred_lr

# Difference between actual and predicted
sns.scatterplot(x=y_pred_lr, y=residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel("Predicted Values")
plt.ylabel("Residuals")
plt.show()

